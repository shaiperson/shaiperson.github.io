<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Plug &amp; Play Worker Pattern - Part III | Blog</title>
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Plug &amp; Play Worker Pattern - Part III" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Note" />
<meta property="og:description" content="Note" />
<link rel="canonical" href="http://localhost:4000/2022/03/02/plug-play-worker-pattern-3.html" />
<meta property="og:url" content="http://localhost:4000/2022/03/02/plug-play-worker-pattern-3.html" />
<meta property="og:site_name" content="Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-03-02T12:55:00-03:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Plug &amp; Play Worker Pattern - Part III" />
<script type="application/ld+json">
{"datePublished":"2022-03-02T12:55:00-03:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2022/03/02/plug-play-worker-pattern-3.html"},"url":"http://localhost:4000/2022/03/02/plug-play-worker-pattern-3.html","description":"Note","headline":"Plug &amp; Play Worker Pattern - Part III","dateModified":"2022-03-02T12:55:00-03:00","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Blog" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Plug &amp; Play Worker Pattern - Part III</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2022-03-02T12:55:00-03:00" itemprop="datePublished">Mar 2, 2022
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <hr />
<p><strong>Note</strong></p>

<p>This is <strong>Part III</strong> of a three-part series.</p>

<ul>
  <li>Part I - use case, pattern concepts</li>
  <li>Part II - naïve implementation</li>
  <li>Part III - pattern implementation</li>
</ul>

<hr />

<h2 id="introduction">Introduction</h2>

<p>In this article series, we develop a design pattern for worker environments that run algorithms on data. The goal of the pattern is to make the environment easily extensible with new algorithms.</p>

<p>In Part I we developed the theory for the pattern, starting from an initial, naïve implementation of a worker environment that does not take extensibility into account, building all the way up to a pattern that attempts to optimize for that property. To also build up to the pattern in the technical realm, we implemented the initial design in Part II to use as a basis for implementing the final design.</p>

<p>Here, in Part III, we code up the final form of the pattern. We then actually go ahead and add new algorithms to the environment in different ways to see the greater extensibility in action and enjoy the fruits of our work!</p>

<h2 id="implementation">Implementation</h2>

<p>Let’s quickly review what we have to do. As we saw in Part I, the pattern in its general form looks like this:</p>

<p><img src="/assets/plug-play-worker-pattern-part-1/Untitled%203.png" style="display: block; margin-left: auto; margin-right: auto; width: 50%;" /></p>

<p>We have a Runner Discovery component responsible for holding a registry of supported algorithms that allows the Controller to discover them. In turn, the “Runner” components have the capacity of running algorithms. They first register with the Discovery component and then listen for algorithm requests over HTTP that the Controller can send when it’s ready. As you can tell, the order of initialization clearly matters. The numbers in the diagram denote this order:</p>

<ol>
  <li>Runner Discovery initializes.</li>
  <li>Runners initialize, POST list of supported algorithms and port to Runner Discovery.</li>
  <li>Controller initializes, GETs algorithm-to-port mapping from Runner Discovery.</li>
  <li>Controller sends algorithm requests to runners until work is done.</li>
</ol>

<p>Now, let’s go ahead and apply this pattern to our worker environment from the previous article. We’ll start with the Runner Discovery, which is both the only brand-new element in our environment and the first one to initialize. Then, we’ll look at how to adapt our runner component to the component. Last, we’ll extend the controller with the necessary code to have it discover the runners automatically.</p>

<h4 id="general-note">General note</h4>

<p>As we did in the previous article when implementing our naïve setup, we’ll Dockerize each component that goes into our worker environment and run all of them in concert using Docker Compose. To make it all work, there are a number of configuration parameters that need to be correctly set in each container of the setup, and we’ll take care to make all of these configurable by environment variables. In each Python projects that requires it, we’ll use the convention of creating a <code class="language-plaintext highlighter-rouge">settings</code> module that picks up all relevant environment variables, validates them and exposes them to other modules.</p>

<p>Similarly to the previous article, we’ll implement everything here in Python. I include some code snippets throughout the article tailored to aid discussion, but you can find the complete working code for the example this GitHub repo. Code for the complete pattern presented here is available in branch <code class="language-plaintext highlighter-rouge">pattern</code>. The code for all components is placed in a single repository. Looking at the repo, you’ll find a directory for each component with its source files, Dockerfile and a <code class="language-plaintext highlighter-rouge">build.sh</code> script. The <code class="language-plaintext highlighter-rouge">worker</code> and <code class="language-plaintext highlighter-rouge">producer</code> directories are there to assist in running and testing everything locally.</p>

<h3 id="runner-discovery">Runner Discovery</h3>

<p>This component has a simple, single responsibility: to function as a discovery service for runners and algorithms. As such, it’ll be a server application exposing a simple API for registering discoverable componentes and reading them. This means it has to:</p>

<ol>
  <li>Provide an endpoint for runners to register themselves and the algorithms they support on.</li>
  <li>Provide an endpoint for the controller to discover runners on when it needs to.</li>
</ol>

<p>Taking from the concepts we laid out in Part I, this functionality is what endows our environment with a <em>dynamic mapping</em> of algorithms to runners.</p>

<p>As in Part II, we’ll leverage FastAPI to write a succinct definition of our API and use Uvicorn to run it.</p>

<p>The model for registration requests consists simply of an <code class="language-plaintext highlighter-rouge">{algorithm, host}</code> pair with the name of an algorithm and the URI of the runner it can be found on.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">uvicorn</span>
<span class="kn">from</span> <span class="nn">fastapi</span> <span class="kn">import</span> <span class="n">FastAPI</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>

<span class="k">class</span> <span class="nc">AlgorithmRegistrationRequest</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">host</span><span class="p">:</span> <span class="nb">str</span>
</code></pre></div></div>

<p>The API allows runners to <code class="language-plaintext highlighter-rouge">POST</code> these <code class="language-plaintext highlighter-rouge">{algorithm, host}</code> pairs for the Discovery component to store in its registry, and to <code class="language-plaintext highlighter-rouge">GET</code> the registry so that the controller learns on which host it can find each algorithm.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">app</span> <span class="o">=</span> <span class="n">FastAPI</span><span class="p">()</span>

<span class="n">registry</span> <span class="o">=</span> <span class="p">{}</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">post</span><span class="p">(</span><span class="s">'/algorithms'</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">register_algorithm</span><span class="p">(</span><span class="n">request</span><span class="p">:</span> <span class="n">AlgorithmRegistrationRequest</span><span class="p">):</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">'Registering algorithm </span><span class="si">{</span><span class="n">request</span><span class="p">.</span><span class="n">algorithm</span><span class="si">}</span><span class="s"> as hosted on </span><span class="si">{</span><span class="n">request</span><span class="p">.</span><span class="n">host</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">registry</span><span class="p">[</span><span class="n">request</span><span class="p">.</span><span class="n">algorithm</span><span class="p">]</span> <span class="o">=</span> <span class="n">request</span><span class="p">.</span><span class="n">host</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'/algorithms'</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">get_registry</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">registry</span>
</code></pre></div></div>

<h3 id="extending-the-runners">Extending the runners</h3>

<p>As we’ve seen, to adapt the runner components to this pattern they now need to notify the Runner Discovery component of the URI on which they’re reachable and the algorithms they support. This is in addition to still exposing the algorithms on HTTP endpoints for the controler to send requests on and running the algorithms themselves.</p>

<p>As we hinted at in Part I when going over the pattern’s theory, the only way we can really make a setup such as this easy enough to develop and maintain is to <em>single-source</em> those environment-related responsibilities of integration with the Discovery and Controller components. In other words, we want to develop the code for these responsibilities separately from the runners themselves, and somehow package the runners with it so that they’re automatically enhanced with those capabilities.</p>

<p>Working with Python, the way we’ll do this is to develop a separate Python project that does all of the environment-related work. We’ll then package that project as a dependency that can be installed in each runner container using <code class="language-plaintext highlighter-rouge">pip</code>. This package will be called <code class="language-plaintext highlighter-rouge">runnerlib</code>.</p>

<p>Also, by developing <code class="language-plaintext highlighter-rouge">runnerlib</code> separately, we can concentrate exclusively on algorithms whenever we’re working on a project responsible for algorithms. For this to work, however, we have to come up with some kind of convention that will make each project’s supported algorithms discoverable by <code class="language-plaintext highlighter-rouge">runnerlib</code> since, at build time, <code class="language-plaintext highlighter-rouge">runnerlib</code> will be naturally agnostic of the runner it will be packaged with in each case. We’ll outline such a convention for the runners to comply with presently.</p>

<h4 id="environment-related-code">Environment-related code</h4>

<p><strong>Discovery</strong></p>

<p>As a first step in developing <code class="language-plaintext highlighter-rouge">runnerlib</code>, let’s create a <code class="language-plaintext highlighter-rouge">disocvery</code> module responsible for interacting with Runner Discovery. This module will expose a function, called <code class="language-plaintext highlighter-rouge">register_all</code>, that discovers the locally supported algorithms and sends registration requests for those algorithms to the Discovery component. This is where a convention for <code class="language-plaintext highlighter-rouge">runnerlib</code> and the runners to agree on becomes necessary: what can we do in our algorithm-running project to make its algorithms easy to discover by a library installed in the same Python environment?</p>

<p>There are many ways to go about this, but let’s just go with one. This is the convention:</p>

<ol>
  <li>Each runner project sports a module called <code class="language-plaintext highlighter-rouge">runner_adapter</code>.</li>
  <li>The <code class="language-plaintext highlighter-rouge">runner_adapter</code> module in each runner exposes one handler function per supported algorithm.</li>
  <li>The name of each handler function is <code class="language-plaintext highlighter-rouge">run_{algorithm-name}</code>.</li>
  <li>The arguments for each handler function are sufficient to run its associated algorithm, are specified with type hints and all types convertible from JSON.</li>
  <li>The return value from each handler is sufficient in capturing the result for the algorithm run and it’s convertible to JSON.</li>
</ol>

<p>The first three requirements allow <code class="language-plaintext highlighter-rouge">runnerlib</code>’s <code class="language-plaintext highlighter-rouge">discovery</code> module to discover the algorithms and the Python functions by which it can run them on data. The fourth requirement allows it to create Pydantic models for each function to use for validation on payloads sent in algorithm-running requests from the Controller. Creating these models with Pydantic also enables easily generating documentation for them. The fifth and last requirement serves to simplify generating the server’s response to each request. In this way, the <code class="language-plaintext highlighter-rouge">runner_adapter</code> serves to interface between the environment-related operations upstream from it and the logic of running and computing algorithm results downstream from it. If any conversions need to be made on what’s returned from downstream algorithm code, they can be made in the adapter to yield a result that complies with this contract.</p>

<p>We’re now ready to code the <code class="language-plaintext highlighter-rouge">register_all</code> function. The function first imports the <code class="language-plaintext highlighter-rouge">runner_adapter</code> module that should be available to import once <code class="language-plaintext highlighter-rouge">runnerlib</code> is installed in a given runner container if the convention is complied with. It then uses <code class="language-plaintext highlighter-rouge">inspect</code> to pick up all <code class="language-plaintext highlighter-rouge">run_{algorithm-name}</code> functions and map each algorithm name to its handler in the <code class="language-plaintext highlighter-rouge">handlers_by_algorithm</code> dict. Finally, it sends <code class="language-plaintext highlighter-rouge">POST</code>s each algorithm to the Discovery component along with the runner’s URI available to it at <code class="language-plaintext highlighter-rouge">settings.host</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urljoin</span>

<span class="kn">import</span> <span class="nn">requests</span>

<span class="kn">from</span> <span class="nn">.setings</span> <span class="kn">import</span> <span class="n">settings</span>

<span class="n">handlers_by_algorithm</span> <span class="o">=</span> <span class="bp">None</span>

<span class="k">def</span> <span class="nf">register_all</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">runner_adapter</span>

    <span class="n">algorithm_handlers</span> <span class="o">=</span> <span class="n">inspect</span><span class="p">.</span><span class="n">getmembers</span><span class="p">(</span>
        <span class="n">runner_adapter</span><span class="p">,</span>
        <span class="n">predicate</span><span class="o">=</span><span class="k">lambda</span> <span class="n">f</span><span class="p">:</span> <span class="n">inspect</span><span class="p">.</span><span class="n">isfunction</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="ow">and</span> <span class="n">re</span><span class="p">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s">'run_*'</span><span class="p">,</span> <span class="n">f</span><span class="p">.</span><span class="n">__name__</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Map each algorithm name to its handler locally
</span>    <span class="k">global</span> <span class="n">handlers_by_algorithm</span>
    <span class="n">handlers_by_algorithm</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'run_'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">function</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">function</span> <span class="ow">in</span> <span class="n">algorithm_handlers</span><span class="p">}</span>

    <span class="c1"># Register each algorithm with runner discovery
</span>    <span class="n">unsuccessful</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">handlers_by_algorithm</span><span class="p">:</span>
        <span class="n">body</span> <span class="o">=</span> <span class="p">{</span><span class="s">'algorithm'</span><span class="p">:</span> <span class="n">algorithm_name</span><span class="p">,</span> <span class="s">'host'</span><span class="p">:</span> <span class="n">settings</span><span class="p">.</span><span class="n">host</span><span class="p">}</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">post</span><span class="p">(</span><span class="n">urljoin</span><span class="p">(</span><span class="n">settings</span><span class="p">.</span><span class="n">runner_discovery_uri</span><span class="p">,</span> <span class="s">'algorithms'</span><span class="p">),</span> <span class="n">json</span><span class="o">=</span><span class="n">body</span><span class="p">)</span>
        <span class="n">response</span><span class="p">.</span><span class="n">raise_for_status</span><span class="p">()</span>
</code></pre></div></div>

<p>In the <code class="language-plaintext highlighter-rouge">discovery</code> module we also expose a getter that returns a handler given an algorithm name:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_handler</span><span class="p">(</span><span class="n">algorithm</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">handlers_by_algorithm</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">algorithm</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Dynamically generated request models</strong></p>

<p>The other environment-related responsibility <code class="language-plaintext highlighter-rouge">runnerlib</code> has to endow our runners with is to spin up a server for the Controller to hit with algorithm-running requests.</p>

<p>As we hinted at before, we can dynamically create Pydantic models for each handler’s expected arguments by using inspection. This is done with Pydantic’s <code class="language-plaintext highlighter-rouge">create_model</code> function that let’s us create a model with fields and types only known at runtime. Because at runtime we know what algorithms our current runner supports, we can also create a Pydantic model to validate the requested algorithm itself is supported. This can be done very comfortably by using FastAPI and defining the algorithm as a path parameter of that Pydantic model’s type.</p>

<p>Let’s first go over the dynamic model creation, implemented in a <code class="language-plaintext highlighter-rouge">models</code> module.</p>

<p>First some imports, and the declaration of a variable that’ll be used by the server code to get the relevant models organized by algorithm. Note that, in particular, we also import <code class="language-plaintext highlighter-rouge">discovery</code>’s <code class="language-plaintext highlighter-rouge">handlers_by_algorithm</code> both to get the set of supported algorithms and because it’s by inspecting these handlers that we can tell what arguments they expect.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">inspect</span>

<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">create_model</span><span class="p">,</span> <span class="n">Extra</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>

<span class="kn">from</span> <span class="nn">.discovery</span> <span class="kn">import</span> <span class="n">handlers_by_algorithm</span>

<span class="n">request_models_by_algorithm</span> <span class="o">=</span> <span class="p">{}</span>
</code></pre></div></div>

<p>We loop over supported algorithms, inspect each handler and generate a Pydantic model dynamically. We also populate a list of algorithm names to use</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>class Config:
    extra = Extra.forbid

# Dynamically create
for name, handler in handlers_by_algorithm.items():
    argspec = inspect.getfullargspec(handler)
    typed_argspec = {field: (typehint, ...) for field, typehint in argspec.annotations.items()}
    request_model = create_model(f'AlgorithmRequestModel_{name}', **typed_argspec, __config__=Config)
    request_models_by_algorithm[name] = request_model
</code></pre></div></div>

<p>Lastly, by iterating over <code class="language-plaintext highlighter-rouge">handlers_by_algorithm</code>’s keys, we can create an enumeration model of supported algorithms:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SupportedAlgorithm</span> <span class="o">=</span> <span class="n">Enum</span><span class="p">(</span><span class="s">'SupportedAlgorithm'</span><span class="p">,</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">name</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">handlers_by_algorithm</span><span class="p">})</span>
</code></pre></div></div>

<p>As a nice bonus, we can add a function in this module that returns the schemas for the generated modules. This can be used to get a quick view of the payloads expected by runners and their algorithm request handlers and create documentation.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_schemas</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">model</span><span class="p">.</span><span class="n">schema</span><span class="p">()</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">request_models_by_algorithm</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>
</code></pre></div></div>

<p><strong>Server</strong></p>

<p>Now, to the server itself.</p>

<p>Aside from server-related dependencies, we import from <code class="language-plaintext highlighter-rouge">models</code> everything we need to run validation in our API as discussed above, and <code class="language-plaintext highlighter-rouge">discovery</code>’s <code class="language-plaintext highlighter-rouge">get_handler</code> that, for each supported algorithm that’s requested, will get us it’s corresponding handler exposed in <code class="language-plaintext highlighter-rouge">runner_adapter</code>.</p>

<p>We define a single <code class="language-plaintext highlighter-rouge">POST</code> endpoint that takes the algorithm to run as a path parameter, and a body that must correspond to that algorithm’s handler’s arguments as defined in <code class="language-plaintext highlighter-rouge">runner_adapter</code>. FastAPI will validate that the algorithm is supported by having declared <code class="language-plaintext highlighter-rouge">algorithm</code> as a path parameter of type <code class="language-plaintext highlighter-rouge">SupportedAlgorithm</code>, and then inside our path operation function we run validation of the body against the model we generated dynamically for the requested algorithm, found in <code class="language-plaintext highlighter-rouge">request_models_by_algorithm</code> exposed by <code class="language-plaintext highlighter-rouge">models</code>. If validation passes, we just invoke the handler passing it the body’s content as arguments and return the result, which will be successfully converted to JSON by FastAPI if the convention from before was followed in coding the container’s <code class="language-plaintext highlighter-rouge">runner_adapter</code>. As in the previous article, <code class="language-plaintext highlighter-rouge">exceptions</code> is a local module defining expected exceptions in our application (find it in the repo).</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">traceback</span>

<span class="kn">import</span> <span class="nn">uvicorn</span>
<span class="kn">from</span> <span class="nn">fastapi</span> <span class="kn">import</span> <span class="n">FastAPI</span><span class="p">,</span> <span class="n">HTTPException</span>
<span class="kn">from</span> <span class="nn">pydantic.error_wrappers</span> <span class="kn">import</span> <span class="n">ValidationError</span>

<span class="kn">from</span> <span class="nn">.models</span> <span class="kn">import</span> <span class="n">SupportedAlgorithm</span><span class="p">,</span> <span class="n">request_models_by_algorithm</span>
<span class="kn">from</span> <span class="nn">.discovery</span> <span class="kn">import</span> <span class="n">get_handler</span>
<span class="kn">import</span> <span class="nn">exceptions</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">FastAPI</span><span class="p">()</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">post</span><span class="p">(</span><span class="s">"/run/{algorithm}"</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">run_algorithm</span><span class="p">(</span><span class="n">algorithm</span><span class="p">:</span> <span class="n">SupportedAlgorithm</span><span class="p">,</span> <span class="n">payload</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="n">algorithm_name</span> <span class="o">=</span> <span class="n">algorithm</span><span class="p">.</span><span class="n">value</span>

    <span class="c1"># Validate payload using dynamically generated algorithm-specific model
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">request_models_by_algorithm</span><span class="p">[</span><span class="n">algorithm_name</span><span class="p">].</span><span class="n">validate</span><span class="p">(</span><span class="n">payload</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">ValidationError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>

    <span class="n">handler</span> <span class="o">=</span> <span class="n">get_handler</span><span class="p">(</span><span class="n">algorithm_name</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">handler</span><span class="p">(</span><span class="o">**</span><span class="n">payload</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">exceptions</span><span class="p">.</span><span class="n">RequestError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="sa">f</span><span class="s">'Error fetching request image, received </span><span class="si">{</span><span class="n">e</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">status_code</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="n">traceback</span><span class="p">.</span><span class="n">format_exc</span><span class="p">())</span>
</code></pre></div></div>

<p>Finally, we also expose a function in the <code class="language-plaintext highlighter-rouge">server</code> module that runs the server:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">run_server</span><span class="p">():</span>
    <span class="n">uvicorn</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><span class="s">"0.0.0.0"</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="n">settings</span><span class="p">.</span><span class="n">port</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Top-level code</strong></p>

<p>Lastly, since all these environment-related concerns essentially make up the initialization process of a runner container, in the Docker command in each runner container we’ll actually run <code class="language-plaintext highlighter-rouge">runnerlib</code> as a top-level module. This means we code the runner’s initialization in <code class="language-plaintext highlighter-rouge">runnerlib</code>’s <code class="language-plaintext highlighter-rouge">__main__</code> module:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">.discovery</span> <span class="kn">import</span> <span class="n">register_all</span>
<span class="n">register_all</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">.server</span> <span class="kn">import</span> <span class="n">run_server</span>
<span class="n">run_server</span><span class="p">()</span>
</code></pre></div></div>

<p>Upon running <code class="language-plaintext highlighter-rouge">python -m runnerlib</code> in a runner container, that runner’s algorithms will get registered with the Discovery component, and it’ll be listening for algorithm-running requests.</p>

<h4 id="complying-with-the-convention">Complying with the convention</h4>

<p>To comply with the convention we came up with for runners to integrate with <code class="language-plaintext highlighter-rouge">runnerlib</code>, we just need to create a <code class="language-plaintext highlighter-rouge">runner_adapter</code> module in each algorithm-running project. By following the five requirements we outlined before, we get the following very simple module code. The algorithm name being <code class="language-plaintext highlighter-rouge">meme_classifier</code>, we define a <code class="language-plaintext highlighter-rouge">run_meme_classifier</code> handler function with a JSON-friendly argument in <code class="language-plaintext highlighter-rouge">image_url</code> that is enough to run the algorithm and a result that upstream concerns can convert to JSON. This handler calls the <code class="language-plaintext highlighter-rouge">run_on_url</code> function we saw in Part II, which remains exactly the same, as well as the rest of the algorithm-running logic itself that is now encapsulated behind the adapter.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">classifier</span>

<span class="k">def</span> <span class="nf">run_meme_classifier</span><span class="p">(</span><span class="n">image_url</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="c1"># logger.info('Running classifier on URL'.format(image_url))
</span>    <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="n">run_on_url</span><span class="p">(</span><span class="n">image_url</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s">'label'</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span> <span class="s">'score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">score</span><span class="p">:.</span><span class="mi">5</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)}</span>
</code></pre></div></div>

<h4 id="packaging-runners-with-runnerlib">Packaging runners with <code class="language-plaintext highlighter-rouge">runnerlib</code></h4>

<p>By installing <code class="language-plaintext highlighter-rouge">runnerlib</code> in a runner’s container, it’s available to run inside it as a top-level module. The command to run the container with is then simply <code class="language-plaintext highlighter-rouge">python -m runnerlib</code>. To install <code class="language-plaintext highlighter-rouge">runnerlib</code>, the Dockerfile I created in the repo simply copies the <code class="language-plaintext highlighter-rouge">runnerlib</code> code found inside the repo to the container image and runs <code class="language-plaintext highlighter-rouge">pip install</code> on it. There are many other ways to install an in-house Python package as a dependency in a container, and the best one will depend on development and CI/CD processes. Note that, in any case, <code class="language-plaintext highlighter-rouge">runnerlib</code> is single-sourced and thus can be developed in one single place, versioned separately and distributed easily to any number of runner containers using a single process.</p>

<h3 id="extending-the-controller">Extending the controller</h3>

<p>The only bit of code missing is to extend the Controller with some logic to get the runner registry from the Discovery component. This is a very simple addition to make: by using the API we defined for Discovery Runner, just send a <code class="language-plaintext highlighter-rouge">GET /algorithms</code> request to it and get a dictionary that maps algorithm names to local runner hosts.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urljoin</span>
<span class="n">runner_registry</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="s">'GET'</span><span class="p">,</span> <span class="n">urljoin</span><span class="p">(</span><span class="n">runner_discovery_uri</span><span class="p">,</span> <span class="s">'algorithms'</span><span class="p">)).</span><span class="n">json</span><span class="p">()</span>
</code></pre></div></div>

<p>If we tweak format of messages sent to the queue to include the name of an algorithm to run alongisde the data to run it on, then the algorithm name can be used to get the corresponding runner host that supports that algorithm by reading <code class="language-plaintext highlighter-rouge">runner_registry</code>. If <code class="language-plaintext highlighter-rouge">algorithm</code> is the field in the queue message’s <code class="language-plaintext highlighter-rouge">body</code> that gives us that name and <code class="language-plaintext highlighter-rouge">payload</code> is the field with the data to run it on (compliant with the runner’s algorithm handler arguments as defined in its <code class="language-plaintext highlighter-rouge">runner_adapter</code>), then the following bit of code gets us home:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">json</span>

<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">algorithm</span> <span class="o">=</span> <span class="n">body</span><span class="p">[</span><span class="s">'algorithm'</span><span class="p">]</span>
<span class="n">payload</span> <span class="o">=</span> <span class="n">body</span><span class="p">[</span><span class="s">'payload'</span><span class="p">]</span>

<span class="n">runner_uri</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">runner_registry</span><span class="p">[</span><span class="n">algorithm</span><span class="p">]</span><span class="si">}</span><span class="s">/run/</span><span class="si">{</span><span class="n">algorithm</span><span class="si">}</span><span class="s">'</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">request</span><span class="p">(</span><span class="s">'POST'</span><span class="p">,</span> <span class="n">runner_uri</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s">'Content-Type'</span><span class="p">:</span> <span class="s">'application/json'</span><span class="p">},</span> <span class="n">data</span><span class="o">=</span><span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">payload</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="dockerization-compose-file">Dockerization, Compose File</h3>

<p>Not much changes in the Dockerfiles we already went over in the Part II, save an addition to the runner’s that installs <code class="language-plaintext highlighter-rouge">runnerlib</code>:</p>

<div class="language-dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">COPY</span><span class="s"> ./runnerlib /opt/lib/runnerlib</span>
<span class="k">WORKDIR</span><span class="s"> /opt/lib/runnerlib</span>
<span class="k">RUN </span>pip <span class="nb">install</span> .
</code></pre></div></div>

<p>As for our brand new Discovery component, its Dockerfile is pretty straightforward as well. The requirements are all to do with setting up its server using FastAPI.</p>
<div class="language-dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">FROM</span><span class="s"> python:3.7</span>
<span class="k">WORKDIR</span><span class="s"> /opt/project</span>
<span class="k">COPY</span><span class="s"> requirements.txt .</span>
<span class="k">RUN </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
<span class="k">COPY</span><span class="s"> ./* ./</span>
</code></pre></div></div>

<p>In turn, the Compose file we use to run and test out our environment gets a new service specification for Discovery Runner and some new environment variables to serve as configuration paramteres. The important additions in the way of configurability have to do with the discovery mechanism we designed. We now have to pass Runner Discovery’s URI to the Controller and runner so that they can communicate with it, and we have to make the runner container know its container name so it can pass it to Runner Discovery when it registers.</p>

<p>As a nice bonus, while we’re updating the Compose file, we can also map the runner container’s port to a host port. This will enable access to its running FastAPI application’s automatically generated <code class="language-plaintext highlighter-rouge">/docs</code> endpoint to get us a useful quick and human-friendly look at its supported algorithms, in addition to the more complete JSON Schema specs we can get by running the <code class="language-plaintext highlighter-rouge">get_schemas</code> function from the runner’s <code class="language-plaintext highlighter-rouge">models</code> module manually.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">runner-discovery</span><span class="pi">:</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">runner-discovery</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">runner-discovery</span>
    <span class="na">command</span><span class="pi">:</span> <span class="s">python main.py</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">PORT=5099</span>

<span class="na">meme-classifier-runner</span><span class="pi">:</span>
    <span class="c1"># ...</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="c1"># ...</span>
      <span class="pi">-</span> <span class="s">CONTAINER_NAME=meme-classifier-runner</span>
      <span class="pi">-</span> <span class="s">PORT=5000</span>
      <span class="pi">-</span> <span class="s">RUNNER_DISCOVERY_CONTAINER_NAME=runner-discovery</span>
      <span class="pi">-</span> <span class="s">RUNNER_DISCOVERY_PORT=5099</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">5000:5000</span>

<span class="na">controller</span><span class="pi">:</span>
    <span class="c1"># ...</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="c1"># ...</span>
      <span class="pi">-</span> <span class="s">RUNNER_DISCOVERY_CONTAINER_NAME=runner-discovery</span>
      <span class="pi">-</span> <span class="s">RUNNER_DISCOVERY_PORT=5099</span>
    <span class="c1"># ...</span>
</code></pre></div></div>

<h3 id="trying-it-out">Trying it out</h3>

<p>Let’s run the same example as in the previous article, just to replicate the same usage and see that it still works.</p>

<p>First, selecting a few logs line from the initialization to see how it’s looking now. We can see the interactions between the runner looking for handlers in the runner’s adapter module, registering them and the controller discovering them by querying the Discovery component.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
meme-classifier-runner    | INFO :: [Discovery] :: Loading runner adapter...
meme-classifier-runner    | INFO :: [Discovery] :: Loading runner adapter members...
meme-classifier-runner    | INFO :: [Discovery] :: Found handlers: run_meme_classifier
meme-classifier-runner    | INFO :: [Discovery] :: Registering algorithm meme_classifier
runner-discovery          | INFO:     172.19.0.5:48300 - "GET /algorithms HTTP/1.1" 200 OK
controller                | INFO :: Obtained runner registry: {'meme_classifier': 'http://meme-classifier-runner:5000'}
...
controller                | INFO :: [+] Listening for messages on queue tasks
</code></pre></div></div>

<p>From a terminal at <code class="language-plaintext highlighter-rouge">./producer/</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py <span class="se">\</span>
meme_classifier <span class="se">\</span>
<span class="s1">'{"image_url": "https://memegenerator.net/img/instances/39673831.jpg"}'</span>
</code></pre></div></div>

<p>Note now the helper script at <code class="language-plaintext highlighter-rouge">./producer/main.py</code> takes an algorithm name as argument as well, since our environment now supports running multiple algorithms and, as we covered before, the message format expected by the controller now includes this parameter.</p>

<p>Logs after sending the message:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>controller                | INFO :: Received message {'algorithm': 'meme_classifier', 'payload': {'image_url': 'https://memegenerator.net/img/instances/39673831.jpg'}}
controller                | INFO :: Calling runner on http://meme-classifier-runner:5000/run/meme_classifier
meme-classifier-runner    | INFO :: [Server] :: Received request to run algorithm SupportedAlgorithm.meme_classifier on payload {'image_url': 'https://memegenerator.net/img/instances/39673831.jpg'}
meme-classifier-runner    | INFO:     172.19.0.5:50060 - "POST /run/meme_classifier HTTP/1.1" 200 OK
controller                | INFO :: Received result from runner: {'result': {'label': 'matrix_morpheus', 'score': 0.99998}}
</code></pre></div></div>

<p>Note the controller sends its request for a run of the meme classifier at <code class="language-plaintext highlighter-rouge">http://meme-classifier-runner:5000</code> which is the URI it received before from the Discovery Runner when sending <code class="language-plaintext highlighter-rouge">GET /algorithms</code> to it.</p>

<h2 id="so-is-it-really-that-extensible">So, is it really that extensible?</h2>

<p>We couldn’t end our discussion of this pattern without really putting it to the test. Since its goal is to make the design easily extensible with new algorithms, the only way to see if it accomplishes this goal is to actually extend it and see how it goes.</p>

<p>You might remember that, in Part I, we motivated designing the pattern by the example of a fictitious image board company that decided it needed to run a meme classifier on images posted to i by users. So to make the test a bit more elegant, let’s actually add some algorithms in the same vain.</p>

<h3 id="adding-a-new-algorithm-to-an-existing-runner-container">Adding a new algorithm to an existing runner container</h3>

<p>Se agrega OCR.</p>

<p>… código, todo nice</p>

<h3 id="adding-a-new-runner-container">Adding a new runner container</h3>

<p>Ahora se agrega detección de idioma, va en otro container porque es otro repo nuevo todo NLP</p>

<h2 id="bonus">Bonus</h2>

<p>La generación dinámica de modelos permite documentación, mostrar script para obtener schemas de runners y cómo quedan los schemas.</p>

<h2 id="conclusions">Conclusions</h2>

<ul>
  <li>Desarrollamos <code class="language-plaintext highlighter-rouge">runner</code> como librería</li>
  <li>El Dockerfile de cada runner va a tener “if prod then instalar de pip else copy e instalar local”</li>
</ul>

<p>Hicimos</p>
<ul>
  <li>Armar librería corrible como módulo</li>
  <li>Hay que setearle PYTHONPATH para que encuentre el integration_adapter</li>
  <li>Hay que setearle PORT</li>
  <li>Hay que setearle CONTAINER_NAME</li>
  <li>(ver cuáles env var más por las dudas)</li>
  <li>Falta hacer el componente runner-discovery</li>
  <li>Cuando corre:
    <ul>
      <li>Primero llama register
        <ul>
          <li>Register asume que hay handlers que empiezan con run_*</li>
        </ul>
      </li>
    </ul>
  </li>
  <li></li>
</ul>

  </div><a class="u-url" href="/2022/03/02/plug-play-worker-pattern-3.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

<!--    <h2 class="footer-heading">Blog</h2>-->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Blog</li><li><a class="u-email" href="mailto:bianchishai@gmail.com">bianchishai@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/shaiperson"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">shaiperson</span></a></li><li><a href="https://www.linkedin.com/in/shaibianchi"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">shaibianchi</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>MS in Computer Science, freelance engineer and entrepreneur</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
